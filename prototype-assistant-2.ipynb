{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.5.2 (SDL 2.28.3, Python 3.11.7)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import threading\n",
    "from pathlib import Path\n",
    "from llama_index.core import Settings\n",
    "from llama_index.core import StorageContext, load_index_from_storage\n",
    "from llm_utils import get_default_settings, create_index, query_index, extract_ingredients_from_text, clean_string\n",
    "from text2speech import text2speech, text2unreal_speech\n",
    "from speech2text import listen, speech2text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm, embed_model, prompt_helper, node_parser = get_default_settings()\n",
    "\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model\n",
    "Settings.prompt_helper = prompt_helper\n",
    "Settings.node_parser = node_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set filepaths\n",
    "proj_dir = Path.cwd()\n",
    "models_dir = proj_dir / 'models'\n",
    "data_dir = proj_dir / 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = data_dir / 'pantry.txt'\n",
    "path_to_cache = proj_dir / 'cache'\n",
    "\n",
    "if os.listdir(path_to_cache) != 0:\n",
    "    # If cache contains files then use it.\n",
    "    storage_context = StorageContext.from_defaults(persist_dir=path_to_cache)\n",
    "    index = load_index_from_storage(storage_context)\n",
    "else:\n",
    "  index = create_index(path_to_data, path_to_cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = create_index(path_to_data, path_to_cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_query():\n",
    "    # Capture user query.\n",
    "    audio = listen()\n",
    "    user_query = speech2text(audio)\n",
    "\n",
    "    if 'no thank you' in user_query.lower():\n",
    "        return False\n",
    "\n",
    "    # Play holding response whilst waiting for actual reponse from llm.\n",
    "    thread = threading.Thread(target=text2unreal_speech, args=(\"One moment. Let me check for you.\",))\n",
    "    thread.start()\n",
    "    response = query_index(index, user_query)\n",
    "    thread.join()\n",
    "\n",
    "    # Print and play llm response.\n",
    "    response_text = response.response\n",
    "    print('Answer: ', response_text)\n",
    "    text2unreal_speech(response_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: do I have tomatoes in the pantry\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Illegal Audio-MPEG-Header 0x00fff3e0 at offset 36094.\n",
      "Note: Trying to resync...\n",
      "Note: Skipped 1 bytes in input.\n",
      "Note: Illegal Audio-MPEG-Header 0x00fff3e0 at offset 36094.\n",
      "Note: Trying to resync...\n",
      "Note: Skipped 1 bytes in input.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:   No, you don't have tomatoes in the pantry as it is mentioned \"Not in stock: Tomato sauce\".\n",
      "Listening...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: no thank you\n"
     ]
    }
   ],
   "source": [
    "text2unreal_speech(\"Hi James, how can I help?\")\n",
    "\n",
    "llm_query()\n",
    "\n",
    "again = True\n",
    "while again:\n",
    "    text2unreal_speech(\"Anything else I can help you with?\")\n",
    "    again = llm_query() \n",
    "\n",
    "text2unreal_speech(\"Ok, speak soon!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "foodmic-QmZOIYsO-python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
